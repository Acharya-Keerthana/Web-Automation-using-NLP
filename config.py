CONFIG = {
    "ollama_model": "tinyllama",  # Or mistral, phi3, etc.
    "ollama_api_url": "http://localhost:11434/api/generate",
    "server_url": "http://localhost:3000/messages",
    "browser": "chromium",
    "headless": False,
}
